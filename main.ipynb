{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple MLP model with LASSO-style regularization\n",
    "class LassoMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LassoMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.beta = nn.Parameter(torch.ones(input_dim))  # Magnitude parameter β for each input feature\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the magnitude parameter β to the input\n",
    "        x = x * self.beta\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define function to train or retrain the neural network\n",
    "def train_network(model, X_train, y_train, lambda_, num_epochs=100, learning_rate=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in tqdm(range(100)):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_train)\n",
    "        loss = criterion(predictions, y_train)\n",
    "\n",
    "        # Add L1 regularization for β to implement LASSO\n",
    "        lasso_penalty = lambda_ * torch.sum(torch.abs(model.beta))\n",
    "        loss += lasso_penalty\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use K-fold cross-validation to find the optimal lambda\n",
    "def select_lambda(X, y, lambdas, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds)\n",
    "    best_lambda = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for lambda_ in lambdas:\n",
    "        print(f\"Testing lambda = {lambda_}\")\n",
    "        scores = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            model = LassoMLP(input_dim=X.shape[1], hidden_dim=64, output_dim=X.shape[1])\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "            print(f\"Training with {len(X_train)} samples, validating with {len(X_val)} samples\")\n",
    "\n",
    "            # Train the model and calculate the validation loss\n",
    "            trained_model = train_network(model, X_train, y_train, lambda_)\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                predictions = trained_model(X_val)\n",
    "                val_loss = mean_squared_error(y_val.numpy(), predictions.numpy())\n",
    "                scores.append(val_loss)\n",
    "\n",
    "        # Take the average score over all folds\n",
    "        avg_score = np.mean(scores)\n",
    "        if avg_score < best_score:\n",
    "            best_score = avg_score\n",
    "            best_lambda = lambda_\n",
    "\n",
    "    return best_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4-5: Iteratively prune features with zero β\n",
    "def lasso_mlp_algorithm(X, y, output_dim, hidden_dim=64, num_epochs=100, learning_rate=0.01, lambdas=[0.01, 0.1, 1.0]):\n",
    "    input_dim = X.shape[1]\n",
    "    output_dim = input_dim\n",
    "    termination = False\n",
    "\n",
    "    c = 0\n",
    "    while not termination:\n",
    "        print(f\"Iteration {c + 1}:\")\n",
    "        # Initialize and train the network\n",
    "        model = LassoMLP(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)\n",
    "        \n",
    "        # Select the optimal lambda\n",
    "        best_lambda = select_lambda(X, y, lambdas)\n",
    "        print(f\"Optimal lambda: {best_lambda}\")\n",
    "\n",
    "        # Train the model with the optimal lambda\n",
    "        trained_model = train_network(model, X, y, best_lambda, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "        # Get the estimated β values\n",
    "        beta_estimates = model.beta.detach().cpu().numpy()\n",
    "        print(\"β values:\", beta_estimates)\n",
    "\n",
    "        # Step 5: Check for termination (if no non-zero β values)\n",
    "        non_zero_beta = beta_estimates != 0\n",
    "        if np.sum(non_zero_beta) == input_dim:  # If all β are non-zero, terminate\n",
    "            termination = True\n",
    "        else:\n",
    "            # Remove features with β = 0 and create a new dataset\n",
    "            X = X[:, non_zero_beta]\n",
    "            input_dim = X.shape[1]  # Update input dimension\n",
    "            c += 1\n",
    "\n",
    "    return trained_model, beta_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/tiagoft/NLP/main/wiki_movie_plots_drama_comedy.csv')\n",
    "\n",
    "x, y = df[\"Plot\"][0:1000], df[\"Genre\"][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Sentence Transformer model...\")\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "x_embeddings = model.encode(x.tolist(), convert_to_tensor=True)\n",
    "y_embeddings = model.encode(y.tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 384]) torch.Size([1000, 384])\n"
     ]
    }
   ],
   "source": [
    "print(x_embeddings.shape, y_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LASSO-MLP algorithm...\n",
      "Iteration 1:\n",
      "Testing lambda = 0.01\n",
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 117.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 119.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 112.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 111.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 104.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lambda = 0.1\n",
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 105.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 114.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 111.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 110.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 104.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lambda = 1.0\n",
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 116.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 108.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 106.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 115.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 800 samples, validating with 200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 118.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal lambda: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 111.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "β values: [ 4.90993261e-06  1.44354999e-06  5.64567745e-06  7.51949847e-06\n",
      "  1.30375847e-05  1.51228160e-05  6.31716102e-06  6.08898699e-06\n",
      "  2.51270831e-06  2.07126141e-06  4.02797014e-06  3.18419188e-06\n",
      "  1.19116157e-06  5.02448529e-06  4.33996320e-06  7.47852027e-07\n",
      "  1.61482021e-05  4.98443842e-06  9.14465636e-06  4.76185232e-06\n",
      "  4.14904207e-06  9.41380858e-06  1.62236392e-06  1.93342566e-06\n",
      "  4.39304858e-06  7.39376992e-06  4.24124300e-06  5.54695725e-06\n",
      "  4.31202352e-06 -9.22009349e-07  3.86126339e-06  1.91852450e-06\n",
      "  8.00937414e-07  9.06642526e-06  4.31854278e-06  9.00030136e-06\n",
      "  5.42309135e-06  4.82238829e-06  8.98633152e-06  2.17650086e-06\n",
      "  3.95905226e-06  4.10526991e-06  7.15255737e-07  5.41377813e-06\n",
      "  5.09340316e-06  2.24355608e-06  1.35786831e-05  1.06627122e-05\n",
      "  3.20188701e-06  4.51318920e-06  6.73532486e-06  1.40350312e-06\n",
      "  8.76002014e-06  1.45155936e-05  2.61701643e-06  1.85705721e-06\n",
      "  4.16301191e-06  2.37580389e-06  9.61218029e-06  4.85777855e-06\n",
      "  1.30385160e-05  3.25590372e-06  2.45589763e-06  5.82076609e-07\n",
      "  5.89434057e-06  3.17580998e-07  1.28056854e-06  1.71363354e-05\n",
      "  1.09616667e-06  4.67337668e-06  5.30760735e-06  3.35834920e-06\n",
      "  2.62632966e-06  1.39791518e-05  2.23610550e-06  1.64005905e-06\n",
      "  8.06059688e-06  2.48290598e-06  3.34344804e-06  9.38400626e-06\n",
      "  4.34461981e-06  1.53854489e-05  6.18398190e-07  2.20444053e-06\n",
      "  1.72015280e-06  2.44844705e-06  4.21609730e-06  4.23192978e-06\n",
      "  1.45193189e-06  4.81121242e-06  1.15325674e-05  2.10655853e-05\n",
      "  3.03704292e-06  1.24145299e-06  5.21074980e-06  1.76485628e-06\n",
      "  1.65859237e-05  5.89620322e-06  2.68872827e-06  4.38932329e-06\n",
      "  5.86453825e-06  4.50201333e-06  2.07098201e-05  5.36348671e-06\n",
      "  1.83749944e-06  1.74902380e-06  2.95042992e-06  9.81613994e-07\n",
      "  1.04401261e-06  2.00048089e-06  5.37093729e-06  1.66613609e-06\n",
      "  5.63189387e-05  1.45006925e-06  1.87568367e-06  1.25477090e-05\n",
      " -1.89058483e-07  1.53016299e-06  4.57931310e-06  2.86009163e-06\n",
      "  5.46127558e-06  5.63915819e-06  5.48548996e-06  5.24055213e-06\n",
      "  1.99582428e-06  1.42585486e-06  1.43982470e-06  9.48086381e-07\n",
      "  3.20095569e-06  4.94439155e-06  1.34389848e-06  5.08222729e-06\n",
      "  6.80144876e-06  2.52760947e-06  4.24403697e-06  7.52974302e-06\n",
      "  3.40584666e-06  1.20382756e-05  5.70341945e-06  8.89785588e-06\n",
      "  2.23983079e-06  6.43357635e-06  5.03659248e-06  6.01541251e-06\n",
      "  9.55536962e-07  1.92970037e-06  3.43006104e-06  1.57952309e-06\n",
      "  3.27639282e-06  5.79375774e-06  1.06636435e-06  1.95950270e-06\n",
      "  5.53391874e-06  2.14390457e-06  3.21213156e-06  1.54934824e-05\n",
      "  2.08523124e-05  2.71759927e-06  4.28408384e-06  5.68479300e-06\n",
      "  1.32275745e-05  1.79465860e-06  4.51412052e-06  8.01961869e-06\n",
      "  4.31668013e-06  4.18443233e-06  9.32253897e-07  3.66475433e-06\n",
      "  5.10271639e-06  5.30853868e-08  1.18883327e-05  1.09607354e-05\n",
      "  8.50297511e-06  1.83470547e-06  6.84149563e-06  1.65654346e-05\n",
      "  1.31037086e-06  1.16704032e-05  1.59069896e-06  1.74436718e-06\n",
      "  2.22306699e-06  6.78747892e-06  1.57207251e-06  1.29872933e-05\n",
      "  3.32389027e-06  1.34166330e-05  2.45403498e-06  3.93018126e-06\n",
      "  6.04987144e-06  7.50459731e-06  1.58976763e-06  2.33016908e-06\n",
      "  2.03680247e-06  3.81469727e-06  4.25241888e-06  2.16439366e-05\n",
      "  1.97719783e-06  1.38022006e-06  6.43357635e-06  1.43330544e-06\n",
      "  2.40933150e-06  4.08291817e-06  1.98446214e-05  1.19991601e-05\n",
      "  4.67710197e-06  5.36441803e-07  3.76161188e-06  6.06663525e-06\n",
      "  1.80676579e-05  1.05891377e-05  3.14414501e-06  2.58535147e-06\n",
      "  6.25569373e-06  7.76536763e-06  8.03265721e-06  5.80679625e-06\n",
      "  2.03400850e-06  9.72859561e-06  9.18284059e-07  2.79117376e-06\n",
      "  3.93204391e-06  3.64147127e-06  1.01234764e-06  9.48086381e-07\n",
      "  1.11637637e-05  4.00934368e-06  3.56603414e-06  8.46385956e-06\n",
      "  4.80841845e-06  1.72201544e-05  6.25941902e-06  1.37416646e-05\n",
      "  1.77044421e-06  5.33461571e-06  1.02147460e-05  5.50597906e-06\n",
      "  9.49017704e-07  4.69107181e-06  2.46064737e-05  7.57817179e-06\n",
      "  4.48338687e-06  1.57579780e-06  2.92342156e-06  1.46683306e-06\n",
      "  2.16281042e-05  1.67731196e-05  2.75205821e-06  9.84128565e-06\n",
      "  3.54181975e-06  4.19747084e-06  4.77395952e-06  8.88761133e-06\n",
      "  4.81307507e-06  3.51667404e-06  5.51249832e-06  3.61446291e-06\n",
      "  1.93715096e-06  3.49059701e-06  4.62774187e-06  4.34555113e-06\n",
      "  3.45148146e-06  9.33930278e-06  8.46013427e-06  2.29105353e-06\n",
      "  7.51763582e-06  6.04614615e-06  1.93528831e-06  3.07615846e-06\n",
      "  2.40281224e-06  7.10692257e-06  1.31595880e-06  1.59442425e-06\n",
      "  3.88361514e-06  7.89761543e-07  6.49131835e-07  5.53950667e-06\n",
      "  1.66967511e-05  1.01113692e-05  1.35423616e-05  1.24517828e-06\n",
      "  1.55614689e-05  1.19023025e-06  2.15694308e-06  1.40536577e-06\n",
      "  3.56975943e-06 -2.69152224e-07  5.07663935e-06  5.81052154e-06\n",
      "  4.97698784e-06  1.50687993e-06  1.87009573e-06  4.13507223e-06\n",
      "  1.15204602e-06  1.21816993e-06  3.58372927e-06  4.12389636e-06\n",
      "  1.27553940e-05  3.84915620e-06  5.21354377e-06  2.42190436e-05\n",
      "  2.28080899e-06  5.84125519e-06  2.43820250e-06  1.12140551e-05\n",
      "  5.03100455e-06  7.32857734e-06  1.81421638e-06  3.60701233e-06\n",
      "  2.06660479e-06  2.21654773e-06  6.17839396e-06  2.41771340e-06\n",
      "  4.52622771e-06  9.93441790e-06  1.51330605e-05  2.71042809e-05\n",
      "  1.46292150e-05  9.05711204e-06  9.94652510e-06  9.48086381e-07\n",
      "  3.42261046e-06  2.13366002e-06  1.69593841e-06  5.08315861e-06\n",
      "  3.19536775e-06  1.41933560e-06  2.33743340e-05  4.65754420e-06\n",
      "  9.99309123e-07  1.13686547e-05  4.47407365e-06  1.85705721e-06\n",
      "  2.40933150e-06  1.24312937e-05  1.17346644e-06  1.36252493e-06\n",
      "  7.13579357e-06  5.50877303e-06  2.47731805e-06  1.47800893e-06\n",
      "  4.55416739e-06  4.84567136e-06  2.60211527e-06  1.07754022e-06\n",
      "  4.73950058e-06  1.50594860e-06  1.45919621e-05  5.22378832e-06\n",
      "  1.02631748e-06  9.58982855e-06  1.70245767e-06  1.59442425e-06\n",
      "  2.36760825e-05  4.24217433e-06  1.53416768e-05  3.56975943e-06\n",
      "  1.76113099e-06  3.40212137e-06  7.39935786e-06  2.73063779e-06\n",
      "  2.71648169e-05  9.01706517e-06  3.71038914e-06  1.15688890e-05\n",
      "  4.25800681e-06  1.79540366e-05  4.24589962e-06  1.64005905e-06\n",
      "  5.88595867e-06  4.13320959e-06  4.58583236e-06  6.01541251e-06\n",
      "  1.26473606e-06  1.07195228e-06  1.31875277e-06  5.68293035e-06\n",
      "  1.49570405e-06  2.25426629e-05  1.43889338e-06  2.45403498e-06\n",
      "  3.57255340e-06  7.91624188e-06  5.66709787e-06  3.36579978e-06]\n",
      "Final β values: [ 4.90993261e-06  1.44354999e-06  5.64567745e-06  7.51949847e-06\n",
      "  1.30375847e-05  1.51228160e-05  6.31716102e-06  6.08898699e-06\n",
      "  2.51270831e-06  2.07126141e-06  4.02797014e-06  3.18419188e-06\n",
      "  1.19116157e-06  5.02448529e-06  4.33996320e-06  7.47852027e-07\n",
      "  1.61482021e-05  4.98443842e-06  9.14465636e-06  4.76185232e-06\n",
      "  4.14904207e-06  9.41380858e-06  1.62236392e-06  1.93342566e-06\n",
      "  4.39304858e-06  7.39376992e-06  4.24124300e-06  5.54695725e-06\n",
      "  4.31202352e-06 -9.22009349e-07  3.86126339e-06  1.91852450e-06\n",
      "  8.00937414e-07  9.06642526e-06  4.31854278e-06  9.00030136e-06\n",
      "  5.42309135e-06  4.82238829e-06  8.98633152e-06  2.17650086e-06\n",
      "  3.95905226e-06  4.10526991e-06  7.15255737e-07  5.41377813e-06\n",
      "  5.09340316e-06  2.24355608e-06  1.35786831e-05  1.06627122e-05\n",
      "  3.20188701e-06  4.51318920e-06  6.73532486e-06  1.40350312e-06\n",
      "  8.76002014e-06  1.45155936e-05  2.61701643e-06  1.85705721e-06\n",
      "  4.16301191e-06  2.37580389e-06  9.61218029e-06  4.85777855e-06\n",
      "  1.30385160e-05  3.25590372e-06  2.45589763e-06  5.82076609e-07\n",
      "  5.89434057e-06  3.17580998e-07  1.28056854e-06  1.71363354e-05\n",
      "  1.09616667e-06  4.67337668e-06  5.30760735e-06  3.35834920e-06\n",
      "  2.62632966e-06  1.39791518e-05  2.23610550e-06  1.64005905e-06\n",
      "  8.06059688e-06  2.48290598e-06  3.34344804e-06  9.38400626e-06\n",
      "  4.34461981e-06  1.53854489e-05  6.18398190e-07  2.20444053e-06\n",
      "  1.72015280e-06  2.44844705e-06  4.21609730e-06  4.23192978e-06\n",
      "  1.45193189e-06  4.81121242e-06  1.15325674e-05  2.10655853e-05\n",
      "  3.03704292e-06  1.24145299e-06  5.21074980e-06  1.76485628e-06\n",
      "  1.65859237e-05  5.89620322e-06  2.68872827e-06  4.38932329e-06\n",
      "  5.86453825e-06  4.50201333e-06  2.07098201e-05  5.36348671e-06\n",
      "  1.83749944e-06  1.74902380e-06  2.95042992e-06  9.81613994e-07\n",
      "  1.04401261e-06  2.00048089e-06  5.37093729e-06  1.66613609e-06\n",
      "  5.63189387e-05  1.45006925e-06  1.87568367e-06  1.25477090e-05\n",
      " -1.89058483e-07  1.53016299e-06  4.57931310e-06  2.86009163e-06\n",
      "  5.46127558e-06  5.63915819e-06  5.48548996e-06  5.24055213e-06\n",
      "  1.99582428e-06  1.42585486e-06  1.43982470e-06  9.48086381e-07\n",
      "  3.20095569e-06  4.94439155e-06  1.34389848e-06  5.08222729e-06\n",
      "  6.80144876e-06  2.52760947e-06  4.24403697e-06  7.52974302e-06\n",
      "  3.40584666e-06  1.20382756e-05  5.70341945e-06  8.89785588e-06\n",
      "  2.23983079e-06  6.43357635e-06  5.03659248e-06  6.01541251e-06\n",
      "  9.55536962e-07  1.92970037e-06  3.43006104e-06  1.57952309e-06\n",
      "  3.27639282e-06  5.79375774e-06  1.06636435e-06  1.95950270e-06\n",
      "  5.53391874e-06  2.14390457e-06  3.21213156e-06  1.54934824e-05\n",
      "  2.08523124e-05  2.71759927e-06  4.28408384e-06  5.68479300e-06\n",
      "  1.32275745e-05  1.79465860e-06  4.51412052e-06  8.01961869e-06\n",
      "  4.31668013e-06  4.18443233e-06  9.32253897e-07  3.66475433e-06\n",
      "  5.10271639e-06  5.30853868e-08  1.18883327e-05  1.09607354e-05\n",
      "  8.50297511e-06  1.83470547e-06  6.84149563e-06  1.65654346e-05\n",
      "  1.31037086e-06  1.16704032e-05  1.59069896e-06  1.74436718e-06\n",
      "  2.22306699e-06  6.78747892e-06  1.57207251e-06  1.29872933e-05\n",
      "  3.32389027e-06  1.34166330e-05  2.45403498e-06  3.93018126e-06\n",
      "  6.04987144e-06  7.50459731e-06  1.58976763e-06  2.33016908e-06\n",
      "  2.03680247e-06  3.81469727e-06  4.25241888e-06  2.16439366e-05\n",
      "  1.97719783e-06  1.38022006e-06  6.43357635e-06  1.43330544e-06\n",
      "  2.40933150e-06  4.08291817e-06  1.98446214e-05  1.19991601e-05\n",
      "  4.67710197e-06  5.36441803e-07  3.76161188e-06  6.06663525e-06\n",
      "  1.80676579e-05  1.05891377e-05  3.14414501e-06  2.58535147e-06\n",
      "  6.25569373e-06  7.76536763e-06  8.03265721e-06  5.80679625e-06\n",
      "  2.03400850e-06  9.72859561e-06  9.18284059e-07  2.79117376e-06\n",
      "  3.93204391e-06  3.64147127e-06  1.01234764e-06  9.48086381e-07\n",
      "  1.11637637e-05  4.00934368e-06  3.56603414e-06  8.46385956e-06\n",
      "  4.80841845e-06  1.72201544e-05  6.25941902e-06  1.37416646e-05\n",
      "  1.77044421e-06  5.33461571e-06  1.02147460e-05  5.50597906e-06\n",
      "  9.49017704e-07  4.69107181e-06  2.46064737e-05  7.57817179e-06\n",
      "  4.48338687e-06  1.57579780e-06  2.92342156e-06  1.46683306e-06\n",
      "  2.16281042e-05  1.67731196e-05  2.75205821e-06  9.84128565e-06\n",
      "  3.54181975e-06  4.19747084e-06  4.77395952e-06  8.88761133e-06\n",
      "  4.81307507e-06  3.51667404e-06  5.51249832e-06  3.61446291e-06\n",
      "  1.93715096e-06  3.49059701e-06  4.62774187e-06  4.34555113e-06\n",
      "  3.45148146e-06  9.33930278e-06  8.46013427e-06  2.29105353e-06\n",
      "  7.51763582e-06  6.04614615e-06  1.93528831e-06  3.07615846e-06\n",
      "  2.40281224e-06  7.10692257e-06  1.31595880e-06  1.59442425e-06\n",
      "  3.88361514e-06  7.89761543e-07  6.49131835e-07  5.53950667e-06\n",
      "  1.66967511e-05  1.01113692e-05  1.35423616e-05  1.24517828e-06\n",
      "  1.55614689e-05  1.19023025e-06  2.15694308e-06  1.40536577e-06\n",
      "  3.56975943e-06 -2.69152224e-07  5.07663935e-06  5.81052154e-06\n",
      "  4.97698784e-06  1.50687993e-06  1.87009573e-06  4.13507223e-06\n",
      "  1.15204602e-06  1.21816993e-06  3.58372927e-06  4.12389636e-06\n",
      "  1.27553940e-05  3.84915620e-06  5.21354377e-06  2.42190436e-05\n",
      "  2.28080899e-06  5.84125519e-06  2.43820250e-06  1.12140551e-05\n",
      "  5.03100455e-06  7.32857734e-06  1.81421638e-06  3.60701233e-06\n",
      "  2.06660479e-06  2.21654773e-06  6.17839396e-06  2.41771340e-06\n",
      "  4.52622771e-06  9.93441790e-06  1.51330605e-05  2.71042809e-05\n",
      "  1.46292150e-05  9.05711204e-06  9.94652510e-06  9.48086381e-07\n",
      "  3.42261046e-06  2.13366002e-06  1.69593841e-06  5.08315861e-06\n",
      "  3.19536775e-06  1.41933560e-06  2.33743340e-05  4.65754420e-06\n",
      "  9.99309123e-07  1.13686547e-05  4.47407365e-06  1.85705721e-06\n",
      "  2.40933150e-06  1.24312937e-05  1.17346644e-06  1.36252493e-06\n",
      "  7.13579357e-06  5.50877303e-06  2.47731805e-06  1.47800893e-06\n",
      "  4.55416739e-06  4.84567136e-06  2.60211527e-06  1.07754022e-06\n",
      "  4.73950058e-06  1.50594860e-06  1.45919621e-05  5.22378832e-06\n",
      "  1.02631748e-06  9.58982855e-06  1.70245767e-06  1.59442425e-06\n",
      "  2.36760825e-05  4.24217433e-06  1.53416768e-05  3.56975943e-06\n",
      "  1.76113099e-06  3.40212137e-06  7.39935786e-06  2.73063779e-06\n",
      "  2.71648169e-05  9.01706517e-06  3.71038914e-06  1.15688890e-05\n",
      "  4.25800681e-06  1.79540366e-05  4.24589962e-06  1.64005905e-06\n",
      "  5.88595867e-06  4.13320959e-06  4.58583236e-06  6.01541251e-06\n",
      "  1.26473606e-06  1.07195228e-06  1.31875277e-06  5.68293035e-06\n",
      "  1.49570405e-06  2.25426629e-05  1.43889338e-06  2.45403498e-06\n",
      "  3.57255340e-06  7.91624188e-06  5.66709787e-06  3.36579978e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the LASSO-MLP algorithm...\")\n",
    "model, final_beta = lasso_mlp_algorithm(x_embeddings, y_embeddings, output_dim=x_embeddings.shape[1])\n",
    "\n",
    "print(\"Final β values:\", final_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
